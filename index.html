<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">

  <!-- CSP ultra-segura corregida -->
  <script>
    const nonce = btoa(String.fromCharCode(...crypto.getRandomValues(new Uint8Array(16))));
    document.head.insertAdjacentHTML(
      "beforeend",
      `<meta http="Content-Security-Policy"
        content="
          default-src 'self';
          script-src 'self' https://cdn.jsdelivr.net 'nonce-${nonce}';
          style-src 'self' 'unsafe-inline';
          img-src 'self' blob: data:;
          connect-src *;
          frame-ancestors 'none';
          media-src *;
          worker-src 'self' blob:;
          object-src 'none';
          base-uri 'self';
        ">
      `
    );
  </script>

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Asistente Visual Inteligente</title>

  <!-- TensorFlow -->
  <script nonce="">
    document.currentScript.setAttribute("nonce", nonce);
  </script>

  <!-- CORRECCI√ìN: agregado tfjs-core y backend-webgl EXPRESAMENTE ‚Üí reduce lag -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.20.0" nonce=""></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.20.0" nonce=""></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.20.0" nonce=""></script>

  <!-- Modelos -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd" nonce=""></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface" nonce=""></script>

  <style>
    body {
      background: #0d1117;
      color: #fff;
      text-align: center;
      margin: 0;
      padding: 20px 0;
      font-family: Arial;
    }
    video {
      width: 90%;
      max-width: 480px;
      border-radius: 14px;
      margin-top: 15px;
    }
    #status {
      margin-top: 20px;
      font-size: 1.3em;
      background: rgba(255,255,255,0.12);
      padding: 10px 20px;
      border-radius: 10px;
      display: inline-block;
    }
    #startButton {
      font-size: 1.5em;
      padding: 12px 25px;
      background: #2ea043;
      border: none;
      border-radius: 15px;
      color: white;
      cursor: pointer;
    }
    #notify {
      position: fixed;
      bottom: 18px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0,0,0,0.75);
      padding: 10px 18px;
      border-radius: 12px;
      opacity: 0;
      transition: 0.25s;
    }
  </style>
</head>

<body>

<h2>üëÅ Asistente Visual Inteligente</h2>
<button id="startButton">Iniciar Asistente</button>
<video id="video" autoplay playsinline></video>

<div id="status">Esperando inicio...</div>
<div id="notify"></div>

<script nonce="">
document.currentScript.setAttribute("nonce", nonce);

/* ---------- UI Utils ---------- */
function notify(msg) {
  const n = document.getElementById("notify");
  n.textContent = msg;
  n.style.opacity = 1;
  setTimeout(() => n.style.opacity = 0, 2200);
}

/* ---------- Variables ---------- */
let video = document.getElementById("video");
let statusDiv = document.getElementById("status");
let startBtn = document.getElementById("startButton");

let cocoModel = null;
let blazeModel = null;

let speaking = false;
let lastMessage = "";
let lastFrame = 0;

/* ---------- VOZ ---------- */
function speak(msg) {
  if (!msg) return;
  if (msg === lastMessage) return;
  try {
    speechSynthesis.cancel();
    const u = new SpeechSynthesisUtterance(msg);
    u.lang = "es-MX";
    speaking = true;
    u.onend = () => { speaking = false; };
    speechSynthesis.speak(u);
    lastMessage = msg;
    statusDiv.textContent = msg;
  } catch (e) {
    console.warn("TTS error:", e);
  }
}

/* ---------- C√°mara ---------- */
async function setupCamera() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: {
        facingMode: "environment",
        width: { ideal: 320 },
        height: { ideal: 240 }
      }
    });
    video.srcObject = stream;
  } catch (e) {
    speak("No se puede acceder a la c√°mara.");
    notify("No se puede acceder a la c√°mara.");
    throw e;
  }
  return new Promise(res => video.onloadedmetadata = () => res());
}

/* ---------- Modelos + BACKEND WebGL ---------- */
async function loadModels() {
  statusDiv.textContent = "Cargando modelos‚Ä¶";

  /** CORRECCI√ìN: ahora s√≠ activa WebGL antes de cargar modelos */
  await tf.setBackend("webgl");
  await tf.ready();

  cocoModel = await cocoSsd.load({ base: "lite_mobilenet_v2" });
  blazeModel = await blazeface.load();

  statusDiv.textContent = "Modelos cargados ‚úî";
}

/* ---------- Histeresis ---------- */
const COUNTER_MAX = 6;
const THRESH_GO = 2;
let personCount = 0, vehicleCount = 0, wallCount = 0, groundCount = 0;

function clamp(n, min=0, max=COUNTER_MAX){ return Math.max(min, Math.min(max, n)); }

function isObstacleOnGroundAdaptive(obj, vw, vh) {
  const [x,y,w,h] = obj.bbox;
  const area = w*h;
  const bottom = y + h;
  const groundZone = vh * 0.65;
  return bottom > groundZone && area > (vw*vh*0.015);
}

/* ---------- Detecci√≥n ---------- */
async function detectFrame(ts) {
  if (ts - lastFrame < 200) return requestAnimationFrame(detectFrame);
  lastFrame = ts;

  if (!cocoModel || !blazeModel) return requestAnimationFrame(detectFrame);

  const cocoDet = await cocoModel.detect(video);
  const blazeDet = await blazeModel.estimateFaces(video, false);

  const preds = [...cocoDet];
  blazeDet.forEach(face => {
    preds.push({
      class: "person",
      score: 0.9,
      bbox: [
        face.topLeft[0],
        face.topLeft[1],
        face.bottomRight[0] - face.topLeft[0],
        face.bottomRight[1] - face.topLeft[1]
      ]
    });
  });

  const vw = video.videoWidth;
  const vh = video.videoHeight;

  let person = false, vehicle = false, wall = false, ground = false;

  for (const obj of preds) {
    const [x,y,w,h] = obj.bbox;
    const area = w*h;

    if (obj.class === "person" && area > vw*vh*0.02) person = true;
    if (["car","truck","bus","motorcycle","bicycle"].includes(obj.class) && area > vw*vh*0.03) vehicle = true;
    if (area > vw*vh*0.55) wall = true;
    if (isObstacleOnGroundAdaptive(obj, vw, vh)) ground = true;
  }

  personCount = clamp(person ? personCount + 1 : personCount - 1);
  vehicleCount = clamp(vehicle ? vehicleCount + 1 : vehicleCount - 1);
  wallCount = clamp(wall ? wallCount + 1 : wallCount - 1);
  groundCount = clamp(ground ? groundCount + 1 : groundCount - 1);

  const pS = personCount >= THRESH_GO;
  const vS = vehicleCount >= THRESH_GO;
  const wS = wallCount >= THRESH_GO;
  const gS = groundCount >= THRESH_GO;

  let msg = "Camino libre.";
  if (wS) msg = "Pared al frente, det√©ngase.";
  else if (pS) msg = "Persona al frente, cuidado.";
  else if (vS) msg = "Veh√≠culo cerca, precauci√≥n.";
  else if (gS) msg = "Obst√°culo en el camino.";

  if (msg !== lastMessage) speak(msg);

  requestAnimationFrame(detectFrame);
}

/* ---------- Inicio ---------- */
async function startApp() {
  startBtn.style.display = "none";
  notify("Activando c√°mara‚Ä¶");

  try {
    await setupCamera();
    notify("C√°mara lista");

    await loadModels();
    notify("Asistente iniciado");

    personCount = vehicleCount = wallCount = groundCount = 0;
    lastMessage = "";

    requestAnimationFrame(detectFrame);
  } catch (e) {
    statusDiv.textContent = "Error cr√≠tico. Revisa permisos.";
    notify("Error iniciando.");
    console.error(e);
  }
}

startBtn.addEventListener("click", startApp);
</script>
</body>
</html>
