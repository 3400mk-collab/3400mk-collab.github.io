<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width,initial-scale=1.0">
  <title>Asistente Visual Inteligente (Opci√≥n B - Optimizado)</title>

  <!--
    CSP pr√°ctica que permite TFJS en GitHub Pages (TFJS utiliza eval/inline en muchos entornos).
    Si luego quieres endurecer la CSP, movemos scripts a archivos externos.
  -->
  <meta http-equiv="Content-Security-Policy" content="
    default-src 'self';
    script-src 'self' https://cdn.jsdelivr.net https://cdn.jsdelivr.net/npm 'unsafe-inline' 'unsafe-eval';
    connect-src *;
    img-src 'self' blob: data:;
    media-src *;
    style-src 'self' 'unsafe-inline';
    object-src 'none';
    frame-ancestors 'none';
  ">

  <!-- TFJS + modelos (lite/mobile). -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>

  <style>
    :root{--green:#2ea043}
    body{
      background:#0d1117;color:#fff;font-family:Segoe UI,Arial,sans-serif;
      margin:0;padding:18px;text-align:center;
    }
    h1{margin:6px 0 12px;font-size:1.1rem}
    #startButton{
      font-size:1.1rem;padding:10px 22px;background:var(--green);border:none;border-radius:12px;color:#fff;
      cursor:pointer;
    }
    video{width:90%;max-width:480px;border-radius:12px;margin-top:12px;background:#000}
    #status{margin-top:12px;display:inline-block;background:rgba(255,255,255,.08);padding:10px 14px;border-radius:10px}
    #notify{position:fixed;left:50%;transform:translateX(-50%);bottom:18px;background:rgba(0,0,0,.75);padding:8px 12px;border-radius:10px;opacity:0;transition:.25s;color:#fff}
    #debugCanvas{position:fixed;right:12px;top:12px;width:160px;height:120px;border:1px solid rgba(255,255,255,.08);display:none}
  </style>
</head>
<body>
  <h1>üëÅ Asistente Visual Inteligente (Opci√≥n B)</h1>
  <button id="startButton">Iniciar Asistente</button>
  <video id="video" autoplay playsinline muted></video>
  <div id="status">Esperando inicio...</div>
  <div id="notify"></div>
  <canvas id="debugCanvas"></canvas>

<script>
/* ============================
   Opci√≥n B - Integraci√≥n optimizada
   - Mantiene la LOGICA de detecci√≥n que solicitaste (niveles bajo/medio/alto).
   - Mejoras: WebGL backend si est√° disponible, rate-limit, resoluci√≥n baja de c√°mara,
     TTS cancel/replace para evitar colas, smoothing/hysteresis.
   - No se cambian umbrales de detecci√≥n (solo adaptaci√≥n relativa al frame en algunos casos).
   ============================ */

const startBtn = document.getElementById('startButton');
const statusDiv = document.getElementById('status');
const notifyBox = document.getElementById('notify');
const video = document.getElementById('video');
const debugCanvas = document.getElementById('debugCanvas');
const debugCtx = (debugCanvas.getContext && debugCanvas.getContext('2d')) || null;

let cocoModel = null;
let blazeModel = null;

let lastMessage = '';
let speaking = false;
let lastFrameTime = 0;

// Hysteresis counters (manteniendo tu l√≥gica)
const COUNTER_MAX = 8;
const THRESH_GO = 2; // frames consecutivos para considerar detectado
let personCnt = 0, vehicleCnt = 0, wallCnt = 0, obsLowCnt = 0, obsMidCnt = 0, obsHighCnt = 0;

// DEBUG: set true para ver canvas de depuraci√≥n (no activo por defecto)
let DEBUG = false;

function notify(msg){
  notifyBox.textContent = msg;
  notifyBox.style.opacity = 1;
  setTimeout(()=> notifyBox.style.opacity = 0, 2200);
}

/* ---------------- TTS mejorado (evita colas y reduce latencia) ---------------- */
function speak(msg){
  if(!msg) return;
  // No repetir el mismo mensaje si ya se est√° hablando
  if(msg === lastMessage && window.speechSynthesis && window.speechSynthesis.speaking) return;
  try{
    if(window.speechSynthesis && window.speechSynthesis.speaking){
      window.speechSynthesis.cancel(); // evita acumulaci√≥n y latencia
    }
    const u = new SpeechSynthesisUtterance(msg);
    u.lang = 'es-MX';
    speaking = true;
    u.onend = ()=> { speaking = false; };
    window.speechSynthesis.speak(u);
    lastMessage = msg;
    statusDiv.textContent = msg;
  }catch(e){
    console.warn('TTS error', e);
  }
}

/* ---------------- C√°mara optimizada (baja resoluci√≥n + framerate limitado) ---------------- */
async function setupCamera(){
  const constraints = {
    audio: false,
    video: {
      facingMode: { ideal: 'environment' },
      width: { ideal: 320 },   // optimizado para m√≥viles
      height: { ideal: 240 },
      frameRate: { ideal: 15, max: 20 }
    }
  };
  try{
    const stream = await navigator.mediaDevices.getUserMedia(constraints);
    video.srcObject = stream;
    video.muted = true; // ayuda con autoplay en m√≥viles
    await new Promise(res => video.onloadedmetadata = res);
    try { await video.play(); } catch(e){ /* ignora si play falla en algunos navegadores */ }
  }catch(e){
    notify('No se puede acceder a la c√°mara.');
    speak('No se puede usar el asistente sin acceso a la c√°mara.');
    throw e;
  }
}

/* ---------------- Cargar modelos + forzar backend WebGL cuando sea posible ---------------- */
async function loadModels(){
  statusDiv.textContent = 'Cargando modelos...';
  notify('Cargando modelos...');
  try{
    if (tf && tf.setBackend){
      try { await tf.setBackend('webgl'); } catch(e){ console.warn('WebGL backend no disponible', e); }
    }
    if (tf && tf.ready) await tf.ready();

    // COCO-SSD lite y BlazeFace (misma combinaci√≥n que funcion√≥ mejor)
    cocoModel = await cocoSsd.load({ base: 'lite_mobilenet_v2' });
    blazeModel = await blazeface.load();

    statusDiv.textContent = 'Modelos cargados ‚úî';
    notify('Modelos listos');
  }catch(e){
    console.error('Error cargando modelos', e);
    statusDiv.textContent = 'Error cargando modelos';
    notify('Error cargando modelos (ver consola)');
    throw e;
  }
}

/* ---------------- Helpers detecci√≥n niveles obst√°culo (id√©ntico al index "mejor detecci√≥n") ---------------- */
function clamp(n,min=0,max=COUNTER_MAX){ return Math.max(min, Math.min(max, n)); }

function obstacleLevels(obj, vw, vh){
  // Devuelve {low:bool, mid:bool, high:bool}
  const [x,y,w,h] = obj.bbox;
  const area = w*h;
  const bottom = y + h;

  const lowZone = vh * 0.70;    // parte baja del frame
  const midZoneTop = vh * 0.35;  // medio
  const highZone = vh * 0.25;    // alto

  const low = (bottom > lowZone) && (area > (vw*vh*0.008)); // >=0.8% area
  const mid = ((y + h/2) > midZoneTop && (y + h/2) <= lowZone) && (area > (vw*vh*0.008));
  const high = (y < highZone) && (area > (vw*vh*0.006));

  return { low, mid, high };
}

/* ---------------- Main detection loop (B) - usaremos la DETECCI√ìN "mejor" exactamente y optimizamos el pipeline ---------------- */
async function detectLoop(ts){
  if(!ts) ts = performance.now();

  // Rate control: objetivo ~6 FPS (160ms)
  if(ts - lastFrameTime < 160) return requestAnimationFrame(detectLoop);
  lastFrameTime = ts;

  if(!cocoModel || !blazeModel) return requestAnimationFrame(detectLoop);

  let cocoDet = [], blazeDet = [];
  try{
    // Llamadas a detect y estimateFaces (pueden lanzar si la c√°mara cambia)
    cocoDet = await cocoModel.detect(video);
    blazeDet = await blazeModel.estimateFaces(video, false);
  }catch(e){
    console.warn('Error durante detecci√≥n:', e);
    return requestAnimationFrame(detectLoop);
  }

  // Mezcla predicciones (mantenemos exactamente la l√≥gica de detecci√≥n que quer√≠as)
  const preds = [...cocoDet];
  blazeDet.forEach(face => preds.push({
    class: 'person',
    score: 0.9,
    bbox: [
      face.topLeft[0],
      face.topLeft[1],
      face.bottomRight[0] - face.topLeft[0],
      face.bottomRight[1] - face.topLeft[1]
    ]
  }));

  const vw = video.videoWidth || 320;
  const vh = video.videoHeight || 240;

  let personPresent = false, vehiclePresent = false, wallPresent = false;
  let anyLow=false, anyMid=false, anyHigh=false;

  // Mant√©n las mismas reglas de umbral que en el index de "mejor detecci√≥n"
  for(const obj of preds){
    const [x,y,w,h] = obj.bbox;
    const area = w*h;

    // Personas (umbral adaptativo)
    if(obj.class === 'person' && area > Math.max(10000, vw*vh*0.01)) personPresent = true;

    // Veh√≠culos
    if(['car','truck','bus','motorcycle'].includes(obj.class) && area > Math.max(18000, vw*vh*0.02)) vehiclePresent = true;

    // Pared
    if(area > vw*vh*0.55) wallPresent = true;

    // Niveles de obst√°culo
    const levels = obstacleLevels(obj, vw, vh);
    if(levels.low) anyLow = true;
    if(levels.mid) anyMid = true;
    if(levels.high) anyHigh = true;
  }

  // Actualizar contadores (smoothing/hysteresis)
  personCnt  = clamp(personPresent  ? personCnt  + 1 : personCnt  - 1);
  vehicleCnt = clamp(vehiclePresent ? vehicleCnt + 1 : vehicleCnt - 1);
  wallCnt    = clamp(wallPresent    ? wallCnt    + 1 : wallCnt    - 1);
  obsLowCnt  = clamp(anyLow  ? obsLowCnt  + 1 : obsLowCnt  - 1);
  obsMidCnt  = clamp(anyMid  ? obsMidCnt  + 1 : obsMidCnt  - 1);
  obsHighCnt = clamp(anyHigh ? obsHighCnt + 1 : obsHighCnt - 1);

  const personStable  = personCnt  >= THRESH_GO;
  const vehicleStable = vehicleCnt >= THRESH_GO;
  const wallStable    = wallCnt    >= THRESH_GO;
  const lowStable     = obsLowCnt  >= THRESH_GO;
  const midStable     = obsMidCnt  >= THRESH_GO;
  const highStable    = obsHighCnt >= THRESH_GO;

  // Prioridad exacta: pared > persona > veh√≠culo > obst√°culo alto>medio>bajo > libre
  let message = 'Camino libre.';
  if(wallStable) message = 'Pared al frente, det√©ngase.';
  else if(personStable) message = 'Persona al frente, cuidado.';
  else if(vehicleStable) message = 'Veh√≠culo cerca, precauci√≥n.';
  else if(highStable) message = 'Objeto alto al frente ‚Äî cuidado.';
  else if(midStable) message = 'Objeto a media altura al frente ‚Äî cuidado.';
  else if(lowStable) message = 'Objeto en el suelo obstruyendo el paso.';

  // S√≥lo hablar si el mensaje cambi√≥ (evita flip-flops)
  if(message !== lastMessage){
    speak(message);
  }

  // Debug draw (opcional)
  if(DEBUG && debugCtx){
    debugCanvas.style.display = 'block';
    debugCanvas.width = 320; debugCanvas.height = 240;
    debugCtx.clearRect(0,0,debugCanvas.width,debugCanvas.height);
    debugCtx.strokeStyle = 'rgba(0,255,0,0.6)';
    debugCtx.lineWidth = 1;
    preds.slice(0,6).forEach(p => {
      const [x,y,w,h] = p.bbox;
      debugCtx.strokeRect(x * (debugCanvas.width/vw), y * (debugCanvas.height/vh), w * (debugCanvas.width/vw), h * (debugCanvas.height/vh));
    });
  } else if(debugCtx) {
    debugCanvas.style.display = 'none';
  }

  requestAnimationFrame(detectLoop);
}

/* ---------------- Start app ---------------- */
async function startApp(){
  startBtn.disabled = true;
  startBtn.style.opacity = '0.6';
  notify('Solicitando c√°mara...');
  statusDiv.textContent = 'Solicitando c√°mara...';

  try{
    await setupCamera();
    notify('C√°mara activada');
    statusDiv.textContent = 'C√°mara lista';

    await loadModels();

    // reset counters & state
    personCnt = vehicleCnt = wallCnt = obsLowCnt = obsMidCnt = obsHighCnt = 0;
    lastMessage = '';

    notify('Asistente iniciado');
    statusDiv.textContent = 'Asistente iniciado';

    // inicia loop de detecci√≥n optimizado
    requestAnimationFrame(detectLoop);

  }catch(e){
    console.error('Error iniciando app:', e);
    statusDiv.textContent = 'Error cr√≠tico. Revisa permisos y consola.';
    notify('No se pudo iniciar. Revisa permisos.');
    startBtn.disabled = false;
    startBtn.style.opacity = '1';
  }
}

startBtn.addEventListener('click', startApp);
</script>
</body>
</html>
